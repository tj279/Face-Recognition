{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7edd99-9a39-494b-9076-edfd59ebc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba1c3d8-02f4-4a8e-97da-f80eedc7c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training images\n",
    "paths = [os.path.join('C:\\\\Users\\\\tanis\\\\new images', f) for f in os.listdir(\"C:\\\\Users\\\\tanis\\\\new images\")]\n",
    "image_data=[]\n",
    "id=[]\n",
    "count=0\n",
    "for path in paths:\n",
    "    count+=1\n",
    "    image=Image.open(path).convert('RGB')\n",
    "    image_data.append(np.array(image,'uint8'))\n",
    "    if (count<=6):\n",
    "        id.append('tanish')\n",
    "    elif (count<=10):\n",
    "        id.append('aks')\n",
    "    else:\n",
    "        id.append('sudhanshu')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3524b02f-7b66-46f5-b988-5bfa79efabfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1261cb-5bb5-4372-bb33-673070f9c591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "face_detector = dlib.get_frontal_face_detector() \n",
    "points_detector = dlib.shape_predictor(\"D:\\\\Computer Vision Masterclass\\\\Weights\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "face_descriptor_extractor = dlib.face_recognition_model_v1(\"D:\\\\Computer Vision Masterclass\\\\Weights\\\\dlib_face_recognition_resnet_model_v1.dat\")\n",
    "face_descriptors=None\n",
    "pred=[]\n",
    "print(len(image_data))\n",
    "count=0\n",
    "ncount=0\n",
    "for image in image_data:\n",
    "    \n",
    "    \n",
    "    face_detections = face_detector(image, 1)\n",
    "    print(len(face_detections))\n",
    "    count+=1\n",
    "    for face in face_detections:\n",
    "        ncount+=1\n",
    "        l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image, (l, t), (r, b), (0, 0, 255), 1)\n",
    "\n",
    "        points = points_detector(image, face)\n",
    "        for point in points.parts():\n",
    "             cv2.circle(image, (point.x, point.y), 2, (0, 255, 0), 1)\n",
    "        \n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image, points)\n",
    "        \n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "        if face_descriptors is None:\n",
    "            face_descriptors = face_descriptor\n",
    "        else:\n",
    "            face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "540d2876-e47f-4cf2-9363-2c56c3a27ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tanish',\n",
       " 'tanish',\n",
       " 'tanish',\n",
       " 'tanish',\n",
       " 'tanish',\n",
       " 'tanish',\n",
       " 'aks',\n",
       " 'aks',\n",
       " 'aks',\n",
       " 'aks',\n",
       " 'sudhanshu',\n",
       " 'sudhanshu',\n",
       " 'sudhanshu',\n",
       " 'sudhanshu',\n",
       " 'sudhanshu']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a2e551-91a3-4c1f-abbb-25d6dc6265e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  tanish\n",
      "predicted:  tanish\n",
      "1\n",
      "actual:  aks\n",
      "predicted:  aks\n",
      "1\n",
      "actual:  aks\n",
      "predicted:  aks\n",
      "1\n",
      "actual:  aks\n",
      "predicted:  aks\n",
      "1\n",
      "actual:  aks\n",
      "predicted:  aks\n",
      "1\n",
      "actual:  sudhanshu\n",
      "predicted:  sudhanshu\n",
      "1\n",
      "actual:  sudhanshu\n",
      "predicted:  sudhanshu\n",
      "1\n",
      "actual:  sudhanshu\n",
      "predicted:  sudhanshu\n",
      "1\n",
      "actual:  sudhanshu\n",
      "predicted:  sudhanshu\n",
      "1\n",
      "actual:  sudhanshu\n",
      "predicted:  sudhanshu\n"
     ]
    }
   ],
   "source": [
    "#test model with training data\n",
    "count=0\n",
    "\n",
    "\n",
    "for image in image_data:\n",
    "    \n",
    "    face_detections = face_detector(image, 1)\n",
    "    print(len(face_detections))\n",
    "    for face in face_detections:\n",
    "        points = points_detector(image, face)\n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image, points)\n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "        dist=np.linalg.norm(face_descriptor-face_descriptors,axis=1)\n",
    "        pred.append(id[dist.argmin()])\n",
    "        print('actual: ',id[count])\n",
    "        print(\"predicted: \",id[dist.argmin()])\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0004eb20-4a55-4198-bc49-df479c589b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get testing data\n",
    "paths = [os.path.join('C:\\\\Users\\\\tanis\\\\test images', f) for f in os.listdir(\"C:\\\\Users\\\\tanis\\\\test images\")]\n",
    "image_data=[]\n",
    "count=0\n",
    "for path in paths:\n",
    "    count+=1\n",
    "    image=Image.open(path).convert('RGB')\n",
    "    image_data.append(np.array(image,'uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3212d59-6908-4edc-81f0-486a7be25266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#test model with new data\n",
    "threshold=1\n",
    "for image in image_data:\n",
    "    face_detections = face_detector(image, 1)\n",
    "    print(len(face_detections))\n",
    "    cv2.putText(image,\"press > for next image\",(200,200), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,255,0))  \n",
    "    cv2.putText(image,\"press q for quit\",(200,250), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,255,0))\n",
    "    for face in face_detections:\n",
    "        ncount+=1\n",
    "        l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image, (l, t), (r, b), (0, 0, 255), 1)\n",
    "        \n",
    "        points = points_detector(image, face)\n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image, points)\n",
    "            \n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "        dist=np.linalg.norm(face_descriptor-face_descriptors,axis=1)\n",
    "            \n",
    "        cv2.putText(image,\"pred: \"+str(id[dist.argmin()]),(l,t), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,255,0))    \n",
    "        cv2.imshow('image',image)\n",
    "    if (cv2.waitKey(0)==ord('>')):\n",
    "        continue\n",
    "        cv2.destroyAllWindows()         \n",
    "    if (cv2.waitKey(0)==ord('q')):\n",
    "        break\n",
    "cv2.destroyAllWindows()        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b1c1a-9941-458e-b17d-fc8f0b60b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "while True:\n",
    "    success,image=cap.read()\n",
    "    image=np.array(image,'uint8')\n",
    "    face_detections = face_detector(image, 1)\n",
    "    for face in face_detections:\n",
    "        l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image, (l, t), (r, b), (0, 0, 255), 1)\n",
    "    \n",
    "        points = points_detector(image, face)\n",
    "        face_descriptor = face_descriptor_extractor.compute_face_descriptor(image, points)\n",
    "        \n",
    "        face_descriptor = [f for f in face_descriptor]\n",
    "        face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "        face_descriptor = face_descriptor[np.newaxis, :]\n",
    "        dist=np.linalg.norm(face_descriptor-face_descriptors,axis=1)\n",
    "        cv2.putText(image,\"pred: \"+str(id[dist.argmin()]),(l,t), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0,255,0))    \n",
    "        \n",
    "        cv2.imshow('image',image)\n",
    "        if (cv2.waitKey(0)==ord('q')):\n",
    "            break\n",
    "cv2.destroyAllWindows()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de3ad-6acf-4d8a-b8ea-42dcbfa59a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
